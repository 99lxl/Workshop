# 度量学习（metric learning）
> 主讲人：张与弛<br>
> 日期：2021-11-04
## 1. 度量学习
### 1.1 度量学习定义
Deep Metric Learning: A Survey：<br>
Metric learning aims to measure the similarity among samples while using an optimal distance metric for learning tasks.<br>
西瓜书：<br>
在机器学习中，对高维数据进行降维的主要目的是希望找到一个合适的低维空间，在此空间中进行学习能比原始空间性能更好。事实上，每个空间对应了在样本属性上定义的一个距离度量，而寻找合适的空间，实质上就是在寻找一个合适的距离度量。那么，为何不直接尝试“学习”出一个合适的距离度量呢？这就是度量学习的基本动机。<br>
总结一下：
- 度量学习的目的是通过一个度量函数来衡量两个样本之间的相似程度
- 为了使度量函数性能更好，通常需要将样本降维映射到一个低维空间中，而这个映射关系，即是度量学习的模型<br>
### 1.2 度量学习的意义
#### 1.2.1 分类问题在部分实际应用中的困境
- 类别总数需要固定
- 训练集的类别需要与实际应用中完全一致
#### 1.2.2 开集问题与闭集问题
- 闭集问题：通常意义上的分类数据集，训练集中样本的种类与测试集中样本的种类完全一致
- 开集问题：训练集中样本的种类与测试集中样本的种类完全不同
- 度量学习是解决开集问题的一种重要方法<br>
### 1.3 度量学习的发展历程
#### 1.3.1 传统机器学习中的度量学习
- 无参数学习线性变换的方法：kNN，PCA
- 线性变换方法：利用马氏距离进行度量，学习度量矩阵
- 非线性变换方法：利用核方法将样本非线性映射到一个高维空间中，再对样本进行降维
#### 1.3.2 深度学习中的度量学习
传统的度量学习方法通常采用线性变换的方式样本进行降维变换，这些方法在处理非线性关系时表现不佳。随着深度学习技术的不断发展，研究者们逐渐将深度学习技术应用于度量学习之中。深度学习技术构建的神经网络能够很好地处理样本数据中的非线性关系，极大推动了度量学习的进步。当前的度量学习的研究主要集中在三个领域：
- 样本挖掘：从样本数据中进行选择与组合，提高网络的训练效率
- 网络架构：对网络架构进行修改与提高
- 损失函数：设计不同的损失函数，使训练出的模型效果更好<br>
### 1.4 适用领域
- 图像：人脸识别、车辆识别、行人重识别
- 语音：语音分离
- 文本：文本分类<br><br>
## 2. 人脸识别中的度量学习
### 2.1 当前人脸识别的基本情况
当前的人脸识别技术遵循度量学习的思路，将人脸图片降维成某维度空间中的一个点，再通过度量函数来衡量不同人脸图片的相似程度，相似程度足够高的图片，就认定为同一个人物的图片。根据度量函数的不同，当前的人脸识别技术主要分为两个路线：
1. 欧几里得距离路线<br>
该技术路线通常比较的是不同样本特征点间的欧几里得距离，欧几里得距离越大，代表两个样本越不同。以该技术路线为代表的架构主要包括Triplet Loss、Contrastive Loss等。
2. 余弦相似度路线<br>
该技术路线比较的是不同样本特征点间的余弦相似度，换句话说，是不同样本特征点之间的夹角。夹角约小，余弦相似度越高，代表两个样本之间越相同。该技术路线是这几年更为流行的一种技术路线，以该技术路线为代表的工作包括Cosface、Arcface等。
### 2.2 Probabilistic Face Embeddings
#### 2.2.1 当前人脸识别的问题所在
众所周知，当前的人脸识别技术已经发展得相对成熟，在门禁、闸机、电子支付等场合已经有了较为广泛的应用。但人脸识别技术在更加不受限制的场合下仍存在很大的性能缺陷，模型会受到遮挡、较强的光线变化或是大尺度的姿势变化的影响，从而产生错误的识别结果。
#### 2.2.2 论文的想法
<p>既然当前的人脸识别模型在各种较为极端的情况下提取出的特征不是十分可靠，那么我们在提取特征时就应当确认提取出的特征是否可靠，并将特征的可靠性作为特征相似度的一个考量标准。由此，作者将不确定性学习的思想引入到了人脸识别的工作之中。</p>
<p>在之前的人脸识别工作中，人们往往将每张图片看作是特征空间中的一个特征点，而在本文中，作者将每张图片看作是特征空间中的一个概率分布采样后的结果，该概率分布含有均值μ和方差δ。在比较两张图片的相似度时，实际上比较的是两个概率分布之间的相似度。通过这样的方法，模型提取出的特征不仅可以区分出不同种类的样本，同时由于方差的存在，特征对于各种极端情况有着更强的鲁棒性。<br></p>
<p>为了衡量不同概率分布间的相似情况，作者提出了一个全新的度量函数：相互似然分数（mutual likelihood score，MLS）</p>

#### 2.2.3 论文的总体创新点
- 将不确定性学习引入到人脸识别之中，将每个人脸图像抽象为一个概率分布，提高了模型的鲁棒性
- 提出了全新的度量函数MLS

#### 2.2.4 论文的不足
- 作者仅仅是在原有的人脸识别网络中添加了一个方差预测模块，所得结果并没有作用于原有的人脸特征提取模块
- 作者提出的度量函数MLS计算量较大，很难进行并行化处理，因此无法直接应用于实际生产之中

#### 2.2.5 可能的启发
个人认为原作者最大的创新点就是引入了不确定性方法，这种方法将原样本看作是某个概率分布采样的结果。而概率分布本身就有一定的鲁棒性，因此这种不确定性学习的思想可能可以用在很多领域中，用以增强模型的鲁棒性。<br><br>
# 3.参考资料
Paper：<br>
[1] Kaya M, Bilge H Ş. Deep metric learning: A survey[J]. Symmetry, 2019, 11(9): 1066.<br>
[2] Deng J, Guo J, Xue N, et al. Arcface: Additive angular margin loss for deep face recognition[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019: 4690-4699.<br>
[3] Shi Y, Jain A K. Probabilistic face embeddings[C]//Proceedings of the IEEE/CVF International Conference on Computer Vision. 2019: 6902-6911.<br>
Blog:<br>
http://aijishu.com/a/1060000000089656<br>
https://blog.csdn.net/leviopku/article/details/102796208<br>
https://zhuanlan.zhihu.com/p/76515370<br>
Book:<br>
《机器学习》周志华